<!doctype html>
<!--
Copyright 2016 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <title>05(a) - VR Audio</title>

    <!--
      This sample demonstrates how to create scenes that align with the space
      physically available to the user (when that information is available.)
    -->

    <style>
      #webgl-canvas {
        box-sizing: border-box;
        height: 100%;
        left: 0;
        margin: 0;
        position: absolute;
        top: 0;
        width: 100%;
      }
    </style>

    <script src="js/third-party/webvr-polyfill.js"></script>

    <script src="js/third-party/gl-matrix-min.js"></script>

    <script src="js/third-party/wglu/wglu-debug-geometry.js"></script>
    <script src="js/third-party/wglu/wglu-program.js"></script>
    <script src="js/third-party/wglu/wglu-stats.js"></script>
    <script src="js/third-party/wglu/wglu-texture.js"></script>

    <script src="js/vr-cube-island.js"></script>
    <script src="js/vr-samples-util.js"></script>
  </head>
  <body>
    <canvas id="webgl-canvas"></canvas>
    <script>
      /* global mat4, WGLUCubeIsland, WGLUTextureLoader, VRSamplesUtil */
      (function () {
      "use strict";


      var ac = new AudioContext();

      var osc = ac.createOscillator();
      var mod = ac.createOscillator();
      
      var gain = ac.createGain();
      var modGain = ac.createGain();

      osc.type = 'sawtooth';
      gain.gain.value = 0.025;

      mod.type = 'square';
      mod.frequency.value = 8;
      modGain.gain.value = 0.025;

      var panner = ac.createPanner();
      panner.panningModel = 'HRTF';
      panner.distanceModel = 'inverse';

      
      osc.connect(gain);
      mod.connect(modGain).connect(gain.gain);

      gain.connect(panner).connect(ac.destination);

      osc.start();
      mod.start();


      var soundPosition = [2, 1.6, 0];

      panner.setPosition.apply(panner, soundPosition);

      var listener = ac.listener;



      var vrDisplay = null;
      var projectionMat = mat4.create();
      var modelViewMat = mat4.create();
      var standingMat = mat4.create();
      var standingPosition = vec3.create();
      var vrPresentButton = null;

      var getListenerPositionDirection = (function() {
        var tmpMat = mat4.create();
        var tmpPosition = vec3.create();
        var tmpDirection = vec3.create();
        var tmpOrientation = quat.create();
        return function (pose) {
          var orientation = pose.orientation;
          var position = pose.position;
          if (!orientation) { orientation = [0, 0, 0, 1]; }
          if (!position) { position = [0, 0, 0]; }

          if (vrDisplay.stageParameters) { 
            mat4.fromRotationTranslation(tmpMat, orientation, position);
            mat4.multiply(tmpMat, vrDisplay.stageParameters.sittingToStandingTransform, modelViewMat);
          } else {
            vec3.add(standingPosition, position, [0, 1.65, 0]);
            mat4.fromRotationTranslation(tmpMat, orientation, standingPosition);
          }

          mat4.getTranslation(tmpPosition, tmpMat);
          mat4.getRotation(tmpOrientation, tmpMat);
          vec3.transformQuat(tmpDirection, [0, 0, -1], tmpOrientation);
          vec3.normalize(tmpDirection, tmpDirection);
          
          return {
            position: tmpPosition,
            direction: tmpDirection
          };
        }
      })();

      // ===================================================
      // WebGL scene setup. This code is not WebVR specific.
      // ===================================================

      // WebGL setup.
      var webglCanvas = document.getElementById("webgl-canvas");
      var gl = null;
      var cubeIsland = null;
      var stats = null;
      var debugGeom = null;

      function initWebGL(preserveDrawingBuffer) {
        var glAttribs = {
          antialias: !VRSamplesUtil.isMobile(),
          preserveDrawingBuffer: preserveDrawingBuffer
        };
        gl = webglCanvas.getContext("webgl", glAttribs);
        gl.clearColor(0.1, 0.2, 0.3, 1.0);
        gl.enable(gl.DEPTH_TEST);
        gl.enable(gl.CULL_FACE);

        var textureLoader = new WGLUTextureLoader(gl);
        var texture = textureLoader.loadTexture("media/textures/cube-sea.png");

        // If the VRDisplay doesn't have stageParameters we won't know
        // how big the users play space. Construct a scene around a
        // default space size like 2 meters by 2 meters as a placeholder.
        cubeIsland = new VRCubeIsland(gl, texture, 2, 2);

        stats = new WGLUStats(gl);
        debugGeom = new WGLUDebugGeometry(gl);

        // Wait until we have a WebGL context to resize and start rendering.
        window.addEventListener("resize", onResize, false);
        onResize();
        window.requestAnimationFrame(onAnimationFrame);
      }

      // ================================
      // WebVR specific code begins here.
      // ================================

      function onVRRequestPresent () {
        vrDisplay.requestPresent({ source: webglCanvas }).then(function () {
        }, function () {
          VRSamplesUtil.addError("requestPresent failed.", 2000);
        });
      }

      function onVRExitPresent () {
        vrDisplay.exitPresent().then(function () {
        }, function () {
          VRSamplesUtil.addError("exitPresent failed.", 2000);
        });
      }

      function onVRPresentChange () {
        onResize();

        if (vrDisplay.isPresenting) {
          if (vrDisplay.capabilities.hasExternalDisplay) {
            VRSamplesUtil.removeButton(vrPresentButton);
            vrPresentButton = VRSamplesUtil.addButton("Exit VR", "media/icons/cardboard64.png", onVRExitPresent);
          }
        } else {
          if (vrDisplay.capabilities.hasExternalDisplay) {
            VRSamplesUtil.removeButton(vrPresentButton);
            vrPresentButton = VRSamplesUtil.addButton("Enter VR", "media/icons/cardboard64.png", onVRRequestPresent);
          }
        }
      }

      if (navigator.getVRDisplays) {
        navigator.getVRDisplays().then(function (displays) {
          if (displays.length > 0) {
            vrDisplay = displays[0];

            initWebGL(true);

            if (vrDisplay.stageParameters) {
              // If we have stageParameters use that to resize our scene to
              // match the users available space more closely.
              cubeIsland.resize(vrDisplay.stageParameters.sizeX, vrDisplay.stageParameters.sizeZ);
            } else {
              VRSamplesUtil.addInfo("VRDisplay did not report stageParameters", 3000);
              // Resetting the pose in standing space isn't useful, because the
              // headset should always be relative to the physical room.
              VRSamplesUtil.addButton("Reset Pose", null, function() { vrDisplay.resetPose(); });
            }

            if (vrDisplay.capabilities.canPresent)
              vrPresentButton = VRSamplesUtil.addButton("Enter VR", "media/icons/cardboard64.png", onVRRequestPresent);

            window.addEventListener('vrdisplaypresentchange', onVRPresentChange, false);
          } else {
            initWebGL(false);
            VRSamplesUtil.addInfo("WebVR supported, but no VRDisplays found.", 3000);
          }
        });
      } else {
        initWebGL(false);
        VRSamplesUtil.addError("Your browser does not support WebVR. See <a href='http://webvr.info'>webvr.info</a> for assistance.");
      }

      function onResize () {
        if (vrDisplay && vrDisplay.isPresenting) {
          var leftEye = vrDisplay.getEyeParameters("left");
          var rightEye = vrDisplay.getEyeParameters("right");

          webglCanvas.width = Math.max(leftEye.renderWidth, rightEye.renderWidth) * 2;
          webglCanvas.height = Math.max(leftEye.renderHeight, rightEye.renderHeight);
        } else {
          webglCanvas.width = webglCanvas.offsetWidth * window.devicePixelRatio;
          webglCanvas.height = webglCanvas.offsetHeight * window.devicePixelRatio;
        }
      }

      function renderSceneView (pose, eye) {
        var orientation = pose.orientation;
        var position = pose.position;
        if (!orientation) { orientation = [0, 0, 0, 1]; }
        if (!position) { position = [0, 0, 0]; }

        if (eye)
          mat4.perspectiveFromFieldOfView(projectionMat, eye.fieldOfView, 0.1, 1024.0);
        else
          mat4.perspective(projectionMat, 45, webglCanvas.width / webglCanvas.height, 0.1, 1024.0);

        if (vrDisplay.stageParameters) {
          // If the headset provides stageParameters use the
          // sittingToStandingTransform to transform the pose into a space where
          // the floor in the center of the users play space is the origin.
          mat4.fromRotationTranslation(modelViewMat, orientation, position);
          mat4.multiply(modelViewMat, vrDisplay.stageParameters.sittingToStandingTransform, modelViewMat);
          if (eye)
            mat4.translate(modelViewMat, modelViewMat, eye.offset);
          mat4.invert(modelViewMat, modelViewMat);
        } else {
          // Otherwise you'll want to translate the view to compensate for the
          // scene floor being at Y=0. Ideally this should match the user's
          // height (you may want to make it configurable). For this demo we'll
          // just assume all human beings are 1.65 meters (~5.4ft) tall.
          vec3.add(standingPosition, position, [0, 1.65, 0]);
          mat4.fromRotationTranslation(modelViewMat, orientation, standingPosition);
          if (eye)
            mat4.translate(modelViewMat, modelViewMat, eye.offset);
          mat4.invert(modelViewMat, modelViewMat);
        }

        cubeIsland.render(projectionMat, modelViewMat, stats);

        debugGeom.bind(projectionMat, modelViewMat);
        debugGeom.drawCube(orientation, position, 0.2, [0, 0, 1, 1]);

        // Draw sound cube.
        var vrListener = getListenerPositionDirection(pose);
        

        // vec3.add(vrListener.direction)

        debugGeom.drawCube(null, soundPosition, 0.4, [1, 0, 0, 1]);

        var _orientation = vrListener.direction;
        listener.setOrientation(_orientation[0], _orientation[1], _orientation[2], 0, 1, 0);
      }

      function onAnimationFrame (t) {
        stats.begin();

        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        if (vrDisplay) {
          vrDisplay.requestAnimationFrame(onAnimationFrame);

          var pose = vrDisplay.getPose();

          if(vrDisplay.isPresenting) {
            gl.viewport(0, 0, webglCanvas.width * 0.5, webglCanvas.height);
            renderSceneView(pose, vrDisplay.getEyeParameters("left"));

            gl.viewport(webglCanvas.width * 0.5, 0, webglCanvas.width * 0.5, webglCanvas.height);
            renderSceneView(pose, vrDisplay.getEyeParameters("right"));

            vrDisplay.submitFrame(pose);
          } else {
            gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
            renderSceneView(pose, null);
            stats.renderOrtho();
          }
        } else {
          window.requestAnimationFrame(onAnimationFrame);

          // No VRDisplay found.
          gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
          mat4.perspective(projectionMat, 45, webglCanvas.width / webglCanvas.height, 0.1, 1024.0);
          mat4.identity(modelViewMat);
          mat4.translate(modelViewMat, modelViewMat, [0, -1.65, 0]);
          cubeIsland.render(projectionMat, modelViewMat, stats);

          stats.renderOrtho();
        }

        stats.end();
      }
      })();
    </script>
  </body>
</html>
