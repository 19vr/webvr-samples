<!doctype html>
<!--
Copyright 2016 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <title>08 - VR audio</title>

    <!--
      This sample demonstrates how to use WebAudio to play properly spatialized
      audio for the users head position.
    -->

    <style>
      #webgl-canvas {
        box-sizing: border-box;
        height: 100%;
        left: 0;
        margin: 0;
        position: absolute;
        top: 0;
        width: 100%;
      }
    </style>

    <script src="js/third-party/gl-matrix-min.js"></script>

    <script src="js/third-party/wglu/wglu-debug-geometry.js"></script>
    <script src="js/third-party/wglu/wglu-program.js"></script>
    <script src="js/third-party/wglu/wglu-stats.js"></script>
    <script src="js/third-party/wglu/wglu-texture.js"></script>

    <script src="js/third-party/webvr-polyfill.js"></script>

    <script src="js/vr-cube-island.js"></script>
    <script src="js/vr-samples-util.js"></script>
    <script src="js/vr-audio-panner.js"></script>
  </head>
  <body>
    <canvas id="webgl-canvas"></canvas>
    <script>
      /* global mat4, WGLUCubeIsland, WGLUTextureLoader, VRSamplesUtil */
      (function () {
      "use strict";

      var PLAYER_HEIGHT = 1.65;

      var vrDisplay = null;
      var projectionMat = mat4.create();
      var poseMat = mat4.create();
      var viewMat = mat4.create();
      var standingMat = mat4.create();
      var standingPosition = vec3.create();
      var vrPresentButton = null;


      // ================================================================
      // WebGL and WebAudio scene setup. This code is not WebVR specific.
      // ================================================================

      // WebGL setup.
      var webglCanvas = document.getElementById("webgl-canvas");
      var gl = null;
      var cubeIsland = null;
      var stats = null;
      var debugGeom = null;

      function initWebGL(preserveDrawingBuffer) {
        var glAttribs = {
          antialias: !VRSamplesUtil.isMobile(),
          preserveDrawingBuffer: preserveDrawingBuffer
        };
        gl = webglCanvas.getContext("webgl", glAttribs);
        gl.clearColor(0.1, 0.2, 0.3, 1.0);
        gl.enable(gl.DEPTH_TEST);
        gl.enable(gl.CULL_FACE);

        var textureLoader = new WGLUTextureLoader(gl);
        var texture = textureLoader.loadTexture("media/textures/cube-sea.png");

        if (vrDisplay && vrDisplay.stageParameters) {
          cubeIsland = new VRCubeIsland(gl, texture, vrDisplay.stageParameters.sizeX, vrDisplay.stageParameters.sizeZ);
        } else {
          cubeIsland = new VRCubeIsland(gl, texture, 2, 2);
        }

        stats = new WGLUStats(gl);
        debugGeom = new WGLUDebugGeometry(gl);

        // Wait until we have a WebGL context to resize and start rendering.
        window.addEventListener("resize", onResize, false);
        onResize();
        window.requestAnimationFrame(onAnimationFrame);
      }

      // WebAudio setup.
      var isAudioPannerReady = false;
      var drumSource, guitarSource, percSource;
      var soundFileData = [{
          name: 'drums',
          url: 'media/sound/drums.ogg'
        }, {
          name: 'guitar',
          url: 'media/sound/guitar.ogg'
        }, {
          name: 'perc',
          url: 'media/sound/perc.ogg'
        }];

      function initAudio(buffers) {
        drumSource = VRAudioPanner.createTestSource({
          buffer: buffers.get('drums'),
          gain: 0.75,
          position: [0, PLAYER_HEIGHT, 1],
          orientation: [0, 0, 0]
        });

        guitarSource = VRAudioPanner.createTestSource({
          buffer: buffers.get('guitar'),
          gain: 0.75,
          position: [-1, PLAYER_HEIGHT, 0],
          orientation: [0, 0, 0]
        });

        percSource = VRAudioPanner.createTestSource({
          buffer: buffers.get('perc'),
          gain: 0.75,
          position: [1, PLAYER_HEIGHT, 0],
          orientation: [0, 0, 0]
        });

        drumSource.start();
        guitarSource.start();
        percSource.start();

        isAudioPannerReady = true;
      }

      // Initiate Audio and then WebGL.
      function init(preserveDrawingBuffer) {
        // Load sound files and then initiate WebAudio/WebGL.
        VRAudioPanner
          .loadAudioFiles(soundFileData, null)
          .then(initAudio)
          .then(function () {
            initWebGL(preserveDrawingBuffer);
          });
      }


      // ================================
      // WebVR specific code begins here.
      // ================================

      function onVRRequestPresent () {
        vrDisplay.requestPresent({ source: webglCanvas }).then(function () {
        }, function () {
          VRSamplesUtil.addError("requestPresent failed.", 2000);
        });
      }

      function onVRExitPresent () {
        vrDisplay.exitPresent().then(function () {
        }, function () {
          VRSamplesUtil.addError("exitPresent failed.", 2000);
        });
      }

      function onVRPresentChange () {
        onResize();

        if (vrDisplay.isPresenting) {
          if (vrDisplay.capabilities.hasExternalDisplay) {
            VRSamplesUtil.removeButton(vrPresentButton);
            vrPresentButton = VRSamplesUtil.addButton("Exit VR", "media/icons/cardboard64.png", onVRExitPresent);
          }
        } else {
          if (vrDisplay.capabilities.hasExternalDisplay) {
            VRSamplesUtil.removeButton(vrPresentButton);
            vrPresentButton = VRSamplesUtil.addButton("Enter VR", "media/icons/cardboard64.png", onVRRequestPresent);
          }
        }
      }

      if (navigator.getVRDisplays) {
        navigator.getVRDisplays().then(function (displays) {
          if (displays.length > 0) {
            vrDisplay = displays[0];

            init(true);

            if (!vrDisplay.stageParameters) {
              VRSamplesUtil.addButton("Reset Pose", null, function() { vrDisplay.resetPose(); });
            }

            if (vrDisplay.capabilities.canPresent)
              vrPresentButton = VRSamplesUtil.addButton("Enter VR", "media/icons/cardboard64.png", onVRRequestPresent);

            window.addEventListener('vrdisplaypresentchange', onVRPresentChange, false);
          } else {
            init(false);
            VRSamplesUtil.addInfo("WebVR supported, but no VRDisplays found.", 3000);
          }
        });
      } else {
        init(false);
        VRSamplesUtil.addError("Your browser does not support WebVR. See <a href='http://webvr.info'>webvr.info</a> for assistance.");
      }

      function onResize () {
        if (vrDisplay && vrDisplay.isPresenting) {
          var leftEye = vrDisplay.getEyeParameters("left");
          var rightEye = vrDisplay.getEyeParameters("right");

          webglCanvas.width = Math.max(leftEye.renderWidth, rightEye.renderWidth) * 2;
          webglCanvas.height = Math.max(leftEye.renderHeight, rightEye.renderHeight);
        } else {
          webglCanvas.width = webglCanvas.offsetWidth * window.devicePixelRatio;
          webglCanvas.height = webglCanvas.offsetHeight * window.devicePixelRatio;
        }
      }

      function getPoseMatrix(out, pose) {
        var orientation = pose.orientation;
        var position = pose.position;
        if (!orientation) { orientation = [0, 0, 0, 1]; }
        if (!position) { position = [0, 0, 0]; }

        if (vrDisplay.stageParameters) {
          mat4.fromRotationTranslation(out, orientation, position);
          mat4.multiply(out, vrDisplay.stageParameters.sittingToStandingTransform, out);
        } else {
          vec3.add(standingPosition, position, [0, PLAYER_HEIGHT, 0]);
          mat4.fromRotationTranslation(out, orientation, standingPosition);
        }
      }

      function renderSceneView (poseInMat, eye) {
        if (eye) {
          mat4.translate(viewMat, poseInMat, eye.offset);
          mat4.perspectiveFromFieldOfView(projectionMat, eye.fieldOfView, 0.1, 1024.0);
          mat4.invert(viewMat, viewMat);
        } else {
          mat4.perspective(projectionMat, 45, webglCanvas.width / webglCanvas.height, 0.1, 1024.0);
          mat4.invert(viewMat, poseInMat);
        }

        cubeIsland.render(projectionMat, viewMat, stats);

        // Draw cubes at the position of each audio source.
        // (Red: Drum, Green: Guitar, Blue: Percussion)
        if (isAudioPannerReady) {
          debugGeom.bind(projectionMat, viewMat);
          debugGeom.drawCube(null, drumSource.getPosition(), 0.2, [1, 0, 0, 1]);
          debugGeom.drawCube(null, guitarSource.getPosition(), 0.2, [0, 1, 0, 1]);
          debugGeom.drawCube(null, percSource.getPosition(), 0.2, [0, 0, 1, 1]);
        }
      }

      // For WebAudio we want to get the position of the listener and a vector
      // representing the direction they're facing. This utility function takes
      // a matrix representing the pose (not inverted) and returns WebAudio
      // compatible vectors. If you're not doing a room scale scene you can use
      // the pose position directly and use vec3.transformQuat as shown below
      // to get a direction vector for the orientation quaternion.
      var getListenerPositionDirection = (function() {
        var tmpPosition = vec3.create();
        var tmpDirection = vec3.create();
        var tmpUp = vec3.create();
        var tmpOrientation = quat.create();
        return function (poseMat) {
            mat4.getTranslation(tmpPosition, poseMat);
            mat4.getRotation(tmpOrientation, poseMat);
            vec3.transformQuat(tmpDirection, [0, 0, -1], tmpOrientation);
            vec3.transformQuat(tmpUp, [0, 1, 0], tmpOrientation);
            vec3.normalize(tmpDirection, tmpDirection);
            return {
              position: tmpPosition,
              direction: tmpDirection,
              up: tmpUp
            };
          }
        })();

      function onAnimationFrame (t) {
        stats.begin();

        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        if (vrDisplay) {
          vrDisplay.requestAnimationFrame(onAnimationFrame);

          var pose = vrDisplay.getPose();
          getPoseMatrix(poseMat, pose);

          if(vrDisplay.isPresenting) {
            gl.viewport(0, 0, webglCanvas.width * 0.5, webglCanvas.height);
            renderSceneView(poseMat, vrDisplay.getEyeParameters("left"));

            gl.viewport(webglCanvas.width * 0.5, 0, webglCanvas.width * 0.5, webglCanvas.height);
            renderSceneView(poseMat, vrDisplay.getEyeParameters("right"));

            vrDisplay.submitFrame(pose);
          } else {
            gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
            renderSceneView(poseMat, null);
            stats.renderOrtho();
          }

          // Compute the listener position/direction.
          var listener = getListenerPositionDirection(poseMat);

          // Set the listener position with WebAudio panner.
          VRAudioPanner.setListenerPosition(listener.position);
          VRAudioPanner.setListenerOrientation(listener.direction, listener.up);
        } else {
          window.requestAnimationFrame(onAnimationFrame);

          // No VRDisplay found.
          gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
          mat4.perspective(projectionMat, 45, webglCanvas.width / webglCanvas.height, 0.1, 1024.0);
          mat4.identity(viewMat);
          mat4.translate(viewMat, viewMat, [0, -PLAYER_HEIGHT, 0]);
          cubeIsland.render(projectionMat, viewMat, stats);

          stats.renderOrtho();
        }

        stats.end();
      }
      })();
    </script>
  </body>
</html>
