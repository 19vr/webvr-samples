<!doctype html>
<!--
Copyright (c) 2016, Brandon Jones.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
-->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <title>01 - VR Input</title>

    <!--
      This sample demonstrates how to use the pose information from a VRDisplay
      to control the view of a WebGL scene. Nothing is presented to the
      VRDisplay.
    -->

    <style>
      #webgl-canvas {
        position: absolute;
        width: 100%;
        height: 100%;
        left: 0;
        top: 0;
        margin: 0;
      }
    </style>

    <script src="js/third-party/gl-matrix-min.js"></script>

    <script src="js/third-party/wglu/wglu-program.js"></script>
    <script src="js/third-party/wglu/wglu-stats.js"></script>
    <script src="js/third-party/wglu/wglu-texture.js"></script>
    <script src="js/third-party/wglu/wglu-url.js"></script>

    <script src="js/vr-cube-sea.js"></script>
    <script src="js/vr-samples-util.js"></script>

    <script>
    // Conditionally enable the WebVR polyfill
    var enablePolyfill = WGLUUrl.getBool("polyfill", false);
    if (enablePolyfill) {
      var polyfillScript = document.createElement("script");
      polyfillScript.src = "js/third-party/webvr-polyfill.js";
      document.getElementsByTagName('head')[0].appendChild(polyfillScript);
    }
    </script>
  </head>
  <body>
    <canvas id="webgl-canvas"></canvas>
    <script>
      "use strict";

      var vrDisplay = null;
      var projectionMat = mat4.create();
      var modelViewMat = mat4.create();

      // ===================================================
      // WebGL scene setup. This code is not WebVR specific.
      // ===================================================

      // WebGL setup.
      var webglCanvas = document.getElementById("webgl-canvas");
      var gl = webglCanvas.getContext("webgl");
      gl.clearColor(0.1, 0.2, 0.3, 1.0); // Non-black makes debugging easier.
      gl.enable(gl.DEPTH_TEST);
      gl.enable(gl.CULL_FACE);

      // Load a simple scene consisting of a grid of floating cubes.
      var textureLoader = new WGLUTextureLoader(gl);
      var texture = textureLoader.loadTexture("media/textures/cube-sea.png");
      var cubeSea = new VRCubeSea(gl, texture);

      var stats = new WGLUStats(gl);

      function onResize() {
        webglCanvas.width = webglCanvas.offsetWidth * window.devicePixelRatio;
        webglCanvas.height = webglCanvas.offsetHeight * window.devicePixelRatio;

        // The viewport and projection matrix will change frequently when we
        // begin rendering in stereo, but for now they only need to be updated
        // when the window is resized.
        gl.viewport(0, 0, webglCanvas.width, webglCanvas.height);
        mat4.perspective(projectionMat, 45, webglCanvas.width/webglCanvas.height, 0.1, 1024.0);
      }
      window.addEventListener("resize", onResize, false);
      onResize();

      // ================================
      // WebVR specific code begins here.
      // ================================

      // Since it's a new API not all browsers will have WebVR support. As such
      // it's a good idea to check that the API is available before attempting
      // to call it.
      if (navigator.getVRDisplays) {
        navigator.getVRDisplays().then(function (displays) {
          // Use the first display in the array if one is available. If multiple
          // displays are present you may want to present the user with a way to
          // select which display they wish to use.
          if (displays.length > 0) {
            vrDisplay = displays[0];
          }
        });
      } else {
        VRSamplesUtil.addError("Your browser does not support WebVR. See <a href='http://webvr.info'>webvr.info</a> for assistance.");
      }

      // Main rendering loop
      function onAnimationFrame() {
        stats.begin();

        // The normal requestAnimationFrame is used here because the scene is
        // being not being presented to the VRDisplay, and so should run at the
        // refresh rate of the users monitor instead of the headset.
        window.requestAnimationFrame(onAnimationFrame);

        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        if (vrDisplay) {
          // If a VRDisplay was found, create a matrix based on its pose.
          var pose = vrDisplay.getPose();

          // The pose and orientation may be null if the VRDisplay cannot report
          // them for some reason. In that case, use reasonable defaults:
          var orientation = pose.orientation;
          var position = pose.position;
          if (!orientation) { orientation = [0, 0, 0, 1]; }
          if (!position) { position = [0, 0, 0]; }

          // Create a Model/View matrix from the orientation and position.
          // From the glMatrix docs:
          // Creates a matrix from a quaternion rotation and vector translation
          // This is equivalent to (but much faster than):
          //
          //     mat4.identity(dest);
          //     mat4.translate(dest, vec);
          //     var quatMat = mat4.create();
          //     quat4.toMat4(quat, quatMat);
          //     mat4.multiply(dest, quatMat);
          mat4.fromRotationTranslation(modelViewMat, orientation, position);

          // Invert because we're describing the camera's position in space,
          // so the objects in the scene need to move "in reverse" to get the
          // appropriate effect.
          mat4.invert(modelViewMat, modelViewMat);
        } else {
          // If no VRDisplay was found, create a matrix using a fallback method.
          mat4.identity(modelViewMat);
        }

        // Render the scene using the matrix.
        cubeSea.render(projectionMat, modelViewMat, stats);

        // Render the FPS counter.
        stats.renderOrtho();

        stats.end();
      }
      window.requestAnimationFrame(onAnimationFrame);
    </script>
  </body>
</html>
